{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46406998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from collections import defaultdict, deque\n",
    "import copy\n",
    "\n",
    "# ----------- Normal vectors estimation functions -----------\n",
    "\n",
    "def compute_face_normals_and_areas(mesh):\n",
    "    \"\"\"\n",
    "    Computes normal and area for each triangle face in the mesh.\n",
    "\n",
    "    Returns:\n",
    "        normals (np.ndarray): An (F, 3) array of unit normal vectors for each face.\n",
    "        areas (np.ndarray): A (F,) array of areas for each face.\n",
    "\n",
    "    Method:\n",
    "        - Extract vertex indices for each triangle face.\n",
    "        - Compute two edge vectors of the triangle.\n",
    "        - Use cross product to get the face normal (not normalized).\n",
    "        - Normalize to get unit normals.\n",
    "        - Compute triangle area as half of the magnitude of the cross product.\n",
    "    \"\"\"\n",
    "    faces = mesh.faces.reshape((-1, 4))[:, 1:]\n",
    "    v0 = mesh.points[faces[:, 0]]\n",
    "    v1 = mesh.points[faces[:, 1]]\n",
    "    v2 = mesh.points[faces[:, 2]]\n",
    "    \n",
    "    cross = np.cross(v1 - v0, v2 - v0)\n",
    "    areas = 0.5 * np.linalg.norm(cross, axis=1)\n",
    "    normals = cross / np.maximum(np.linalg.norm(cross, axis=1, keepdims=True), 1e-8)\n",
    "    return normals, areas\n",
    "\n",
    "def build_vertex_to_faces_map(mesh):\n",
    "    \"\"\"\n",
    "    Builds a mapping from each vertex index to the list of face indices that include that vertex.\n",
    "\n",
    "    The same with pyvista's mesh.point_cell_ids()\n",
    "    Returns:\n",
    "        defaultdict(list): A dictionary where each key is a vertex index, and the value is \n",
    "        a list of face indices (from mesh.faces) that contain the vertex.\n",
    "\n",
    "    Example:\n",
    "        {\n",
    "            0: {1, 5, 10},  # vertex 0 is part of faces 1, 5, and 10\n",
    "            1: {0, 2},      # vertex 1 is part of faces 0 and 2\n",
    "            ...\n",
    "        }    \n",
    "    \"\"\"\n",
    "    vertex_faces = defaultdict(list)\n",
    "    faces = mesh.faces.reshape((-1, 4))[:, 1:]\n",
    "    for i, (v1, v2, v3) in enumerate(faces):\n",
    "        vertex_faces[v1].append(i)\n",
    "        vertex_faces[v2].append(i)\n",
    "        vertex_faces[v3].append(i)\n",
    "    return vertex_faces\n",
    "\n",
    "def compute_area_weighted_vertex_normals(mesh):\n",
    "    \"\"\"\n",
    "    Computes unit vertex normals by averaging adjacent face normals, weighted by face area.\n",
    "\n",
    "    Returns:\n",
    "        vertex_normals (np.ndarray): An (N, 3) array of unit normal vectors for each vertex.\n",
    "\n",
    "    Method:\n",
    "        1. Compute face normals and face areas using cross products.\n",
    "        2. Build a mapping from each vertex to the list of adjacent face indices.\n",
    "        3. For each vertex:\n",
    "            - Retrieve adjacent faces.\n",
    "            - Average their normals, weighted by face area.\n",
    "            - Normalize the result to obtain a unit normal.\n",
    "    \"\"\"\n",
    "    face_normals, face_areas = compute_face_normals_and_areas(mesh)\n",
    "    vertex_faces = build_vertex_to_faces_map(mesh)\n",
    "    num_vertices = mesh.points.shape[0]\n",
    "    vertex_normals = np.zeros((num_vertices, 3))\n",
    "\n",
    "    for vi in range(num_vertices):\n",
    "        adjacent_faces = vertex_faces[vi]\n",
    "        if not adjacent_faces:\n",
    "            continue\n",
    "        areas = face_areas[adjacent_faces]\n",
    "        normals = face_normals[adjacent_faces]\n",
    "        weighted_sum = np.sum(normals * areas[:, np.newaxis], axis=0)\n",
    "        vertex_normals[vi] = weighted_sum / np.linalg.norm(weighted_sum)\n",
    "    \n",
    "    return vertex_normals\n",
    "\n",
    "# -------------------------- Normal vector angle --------------\n",
    "\n",
    "def normal_vector_angle(n_p, n_q, degrees=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - n_p, n_q: 3D vectors (can be non-normalized).\n",
    "    - degrees: If True, return angle in degrees. Otherwise, radians.\n",
    "\n",
    "    Returns:\n",
    "    - Angle between vectors\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(n_p, n_q)\n",
    "    norm_p = np.linalg.norm(n_p)\n",
    "    norm_q = np.linalg.norm(n_q)\n",
    "\n",
    "    if norm_p == 0 or norm_q == 0:\n",
    "        return 0.0\n",
    "\n",
    "    cos_theta = np.clip(dot_product / (norm_p * norm_q), -1.0, 1.0)\n",
    "    angle_rad = np.arccos(cos_theta)\n",
    "    return np.degrees(angle_rad) if degrees else angle_rad\n",
    "\n",
    "# ----------------------------------------------\n",
    "def sorting_flat_vertices_with_flatness(f_normals, adjacency):\n",
    "    \"\"\"\n",
    "    Find all flat vertices, compute their flatness (average normal angle to neighbors),\n",
    "    and return them sorted by flatness (ascending).\n",
    "    \n",
    "    Parameters:\n",
    "        f_normals (np.ndarray): An (M, 3) array containing the normal vectors at each face.\n",
    "        adjacency (dict): A dictionary mapping each face to a set of its adjacent faces.\n",
    "        \n",
    "    Returns:\n",
    "        List of (vertex_index, flatness_value) tuples, sorted by flatness_value.\n",
    "    \"\"\"\n",
    "    flat_vertices = []\n",
    "    for vi, neighbors in adjacency.items():\n",
    "        if not neighbors:\n",
    "            continue\n",
    "        # Check if all neighbor angles are below threshold\n",
    "        angles = [normal_vector_angle(f_normals[vi], f_normals[vj]) for vj in neighbors]\n",
    "        flatness = sum(angles) / len(angles)\n",
    "        flat_vertices.append((vi, flatness))\n",
    "        # if all(angle < threshold for angle in angles):\n",
    "        #     flatness = sum(angles) / len(angles)\n",
    "        #     flat_vertices.append((vi, flatness))\n",
    "        \n",
    "    # Sort by flatness value (ascending)\n",
    "    flat_vertices.sort(key=lambda x: x[1])\n",
    "    return flat_vertices\n",
    "\n",
    "def sort_faces_by_flatness(face_normals, face_adjacency):\n",
    "    \"\"\"\n",
    "    Compute 'flatness' of each face by averaging the angle to its neighboring face normals,\n",
    "    then return a list of (face_index, flatness_value) sorted by flatness (ascending).\n",
    "\n",
    "    Parameters:\n",
    "        face_normals (np.ndarray): (M, 3) array of face normal vectors.\n",
    "        face_adjacency (dict[int, set[int]]): adjacency list of faces.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, float]]: list of (face_index, flatness), sorted by flatness.\n",
    "    \"\"\"\n",
    "    flat_faces = []\n",
    "    for fi, neighbors in face_adjacency.items():\n",
    "        if not neighbors:\n",
    "            continue\n",
    "        angles = [normal_vector_angle(face_normals[fi], face_normals[nj]) for nj in neighbors]\n",
    "        flatness = sum(angles) / len(angles)\n",
    "        flat_faces.append((fi, flatness))\n",
    "\n",
    "    flat_faces.sort(key=lambda x: x[1])  # ascending: flatter faces first\n",
    "    return flat_faces\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def compute_face_normals_from_vertex_normals(faces, v_normals):\n",
    "    \"\"\"\n",
    "    Compute the normal vector of each face in a triangular mesh based on the normal vectors of its vertices.\n",
    "\n",
    "    Parameters:\n",
    "        mesh (pyvista.PolyData): A 3D triangular mesh loaded using PyVista.\n",
    "        v_normals (np.ndarray): An (N, 3) array containing the normal vectors at each vertex.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An (M, 3) array containing the normal vector of each face, computed as the average of its three vertices' normals.\n",
    "    \"\"\"\n",
    "    # Average the normal vectors of the three vertices of each face\n",
    "    face_normals = np.mean(v_normals[faces], axis=1)\n",
    "\n",
    "    # Normalize the result\n",
    "    norms = np.linalg.norm(face_normals, axis=1, keepdims=True)\n",
    "    face_normals = face_normals / np.where(norms == 0, 1, norms)  # avoid division by zero\n",
    "\n",
    "    return face_normals\n",
    "\n",
    "\n",
    "def cluster_surface(adj, v_normals, flat_v_sorted, weight, threshold):\n",
    "    flat_v_sorted_copy = deque(flat_v_sorted)  # Faster .popleft()\n",
    "    unvisited = set(range(len(v_normals)))\n",
    "    clusters = []\n",
    "\n",
    "    def compute_avg_angle(normal, neighbors):\n",
    "        return np.mean([\n",
    "            normal_vector_angle(normal, v_normals[nj])\n",
    "            for nj in neighbors\n",
    "        ])\n",
    "\n",
    "    while unvisited:\n",
    "        while flat_v_sorted_copy:\n",
    "            start = flat_v_sorted_copy.popleft()\n",
    "            if start in unvisited:\n",
    "                break\n",
    "        else:\n",
    "            break  # No unvisited nodes left\n",
    "\n",
    "        cluster = set([start])\n",
    "        queue = deque([start])\n",
    "        unvisited.remove(start)\n",
    "\n",
    "        # Maintain running sum of normals for this cluster\n",
    "        normals_sum = v_normals[start].copy()\n",
    "\n",
    "        while queue:\n",
    "            vi = queue.popleft()\n",
    "            for vj in adj[vi]:\n",
    "                if vj not in unvisited:\n",
    "                    continue\n",
    "\n",
    "                # Average angle between vj and its neighbors\n",
    "                avg_angle_vi = compute_avg_angle(v_normals[vi], adj[vj])\n",
    "\n",
    "                # Compute updated cluster normal\n",
    "                cluster_normal = normals_sum / np.maximum(np.linalg.norm(normals_sum), 1e-8)\n",
    "\n",
    "                avg_angle_cluster = compute_avg_angle(cluster_normal, adj[vj])\n",
    "                proximity = weight * avg_angle_vi + (1 - weight) * avg_angle_cluster\n",
    "\n",
    "                if proximity < threshold:\n",
    "                    cluster.add(vj)\n",
    "                    queue.append(vj)\n",
    "                    unvisited.remove(vj)\n",
    "                    normals_sum += v_normals[vj]  # Update running normal sum\n",
    "\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def cluster_surface_face_based(face_adjacency, face_normals, flat_f_sorted, weight=0.5, threshold=10.0):\n",
    "    \"\"\"\n",
    "    Cluster faces on a mesh based on surface flatness and adjacency.\n",
    "\n",
    "    Parameters:\n",
    "        face_adjacency (dict[int, set[int]]): adjacency list of face indices.\n",
    "        face_normals (np.ndarray): (M, 3) array of face normal vectors.\n",
    "        flat_f_sorted (List[Tuple[int, float]]): list of (face_index, flatness), sorted by flatness ascending.\n",
    "        weight (float): weight for combining local and cluster normal angle.\n",
    "        threshold (float): max combined angle (in degrees) to include in the cluster.\n",
    "\n",
    "    Returns:\n",
    "        List[Set[int]]: list of clusters (each a set of face indices).\n",
    "    \"\"\"\n",
    "    flat_f_sorted_copy = deque(flat_f_sorted)\n",
    "    unvisited = set(range(len(face_normals)))\n",
    "    clusters = []\n",
    "\n",
    "    def compute_avg_angle(normal, neighbors):\n",
    "        return np.mean([\n",
    "            normal_vector_angle(normal, face_normals[nj])\n",
    "            for nj in neighbors\n",
    "        ])\n",
    "\n",
    "    while unvisited:\n",
    "        while flat_f_sorted_copy:\n",
    "            start, _ = flat_f_sorted_copy.popleft()\n",
    "            if start in unvisited:\n",
    "                break\n",
    "        else:\n",
    "            break  # No unvisited faces left\n",
    "\n",
    "        cluster = set([start])\n",
    "        queue = deque([start])\n",
    "        unvisited.remove(start)\n",
    "\n",
    "        # Running sum of normals for this cluster\n",
    "        normals_sum = face_normals[start].copy()\n",
    "\n",
    "        while queue:\n",
    "            fi = queue.popleft()\n",
    "            for fj in face_adjacency.get(fi, []):\n",
    "                if fj not in unvisited:\n",
    "                    continue\n",
    "\n",
    "                # Average angle of neighbor fj\n",
    "                avg_angle_local = compute_avg_angle(face_normals[fi], face_adjacency.get(fj, []))\n",
    "\n",
    "                # Cluster average normal\n",
    "                cluster_normal = normals_sum / np.maximum(np.linalg.norm(normals_sum), 1e-8)\n",
    "                avg_angle_cluster = compute_avg_angle(cluster_normal, face_adjacency.get(fj, []))\n",
    "\n",
    "                # Weighted proximity\n",
    "                proximity = weight * avg_angle_local + (1 - weight) * avg_angle_cluster\n",
    "\n",
    "                if proximity < threshold:\n",
    "                    cluster.add(fj)\n",
    "                    queue.append(fj)\n",
    "                    unvisited.remove(fj)\n",
    "                    normals_sum += face_normals[fj]\n",
    "\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "\n",
    "def merge_noise_faces(clusters, vertex_normals, adjacency, K=10):\n",
    "    \"\"\"\n",
    "    Merge small (noise) clusters into neighboring real clusters based on normal similarity,\n",
    "    while avoiding merging adjacent noise clusters together.\n",
    "\n",
    "    Parameters:\n",
    "        clusters (List[Set[int]]): List of vertex index sets (each cluster).\n",
    "        vertex_normals (np.ndarray): (N, 3) array of vertex normals.\n",
    "        adjacency (dict): {vertex_index: set(neighboring vertex indices)}.\n",
    "        K (int): Max vertex count for a cluster to be considered noise.\n",
    "\n",
    "    Returns:\n",
    "        List[Set[int]]: Updated clusters with noise surfaces merged into real surfaces.\n",
    "    \"\"\"\n",
    "    # Separate clusters\n",
    "    real_clusters = [c for c in clusters if len(c) >= K]\n",
    "    noise_clusters = [c for c in clusters if len(c) < K]\n",
    "\n",
    "    # Precompute normals\n",
    "    def cluster_avg_normal(cluster):\n",
    "        normals = [vertex_normals[vi] for vi in cluster]\n",
    "        summed = np.sum(normals, axis=0)\n",
    "        return summed / np.linalg.norm(summed) if np.linalg.norm(summed) > 0 else summed\n",
    "\n",
    "    real_normals = [cluster_avg_normal(c) for c in real_clusters]\n",
    "    noise_normals = [cluster_avg_normal(c) for c in noise_clusters]\n",
    "\n",
    "    # Create index-to-cluster maps for fast lookup\n",
    "    vertex_to_real_cluster = {}\n",
    "    for idx, cluster in enumerate(real_clusters):\n",
    "        for v in cluster:\n",
    "            vertex_to_real_cluster[v] = idx\n",
    "\n",
    "    merged_indices = set()  # track merged noise cluster indices\n",
    "\n",
    "    for ni, noise in enumerate(noise_clusters):\n",
    "        if ni in merged_indices:\n",
    "            continue\n",
    "        noise_normal = noise_normals[ni]\n",
    "\n",
    "        # Find adjacent real clusters only\n",
    "        neighbor_real_candidates = set()\n",
    "        for vi in noise:\n",
    "            for vj in adjacency[vi]:\n",
    "                if vj in vertex_to_real_cluster:\n",
    "                    neighbor_real_candidates.add(vertex_to_real_cluster[vj])\n",
    "\n",
    "        # Find the best matching real cluster by normal vector angle\n",
    "        best_real_idx = None\n",
    "        best_angle = float('inf')\n",
    "\n",
    "        for r_idx in neighbor_real_candidates:\n",
    "            angle = normal_vector_angle(noise_normal, real_normals[r_idx])\n",
    "            if angle < best_angle:\n",
    "                best_real_idx = r_idx\n",
    "                best_angle = angle\n",
    "\n",
    "        # Merge into best-matching real cluster\n",
    "        if best_real_idx is not None:\n",
    "            real_clusters[best_real_idx].update(noise)\n",
    "            merged_indices.add(ni)\n",
    "        # else: discard the noise cluster (could also be kept separately)\n",
    "\n",
    "    return real_clusters\n",
    "\n",
    "\n",
    "def merge_noise_faces_face_based(clusters, face_normals, face_adjacency, K=10):\n",
    "    \"\"\"\n",
    "    Merge small (noise) face clusters into neighboring real clusters based on normal similarity,\n",
    "    while avoiding merging adjacent noise clusters together.\n",
    "\n",
    "    Parameters:\n",
    "        clusters (List[Set[int]]): List of face index sets (each cluster).\n",
    "        face_normals (np.ndarray): (M, 3) array of face normals.\n",
    "        face_adjacency (dict[int, set[int]]): Adjacency list of faces.\n",
    "        K (int): Max face count for a cluster to be considered noise.\n",
    "\n",
    "    Returns:\n",
    "        List[Set[int]]: Updated clusters with noise faces merged into real face clusters.\n",
    "    \"\"\"\n",
    "    # Separate clusters\n",
    "    real_clusters = [c for c in clusters if len(c) >= K]\n",
    "    noise_clusters = [c for c in clusters if len(c) < K]\n",
    "\n",
    "    # Compute average normal of a cluster\n",
    "    def cluster_avg_normal(cluster):\n",
    "        normals = [face_normals[fi] for fi in cluster]\n",
    "        summed = np.sum(normals, axis=0)\n",
    "        norm = np.linalg.norm(summed)\n",
    "        return summed / norm if norm > 0 else summed\n",
    "\n",
    "    real_normals = [cluster_avg_normal(c) for c in real_clusters]\n",
    "    noise_normals = [cluster_avg_normal(c) for c in noise_clusters]\n",
    "\n",
    "    # Map each face to its real cluster (for fast lookup)\n",
    "    face_to_real_cluster = {}\n",
    "    for idx, cluster in enumerate(real_clusters):\n",
    "        for f in cluster:\n",
    "            face_to_real_cluster[f] = idx\n",
    "\n",
    "    merged_indices = set()  # to skip already-merged noise clusters\n",
    "\n",
    "    for ni, noise in enumerate(noise_clusters):\n",
    "        if ni in merged_indices:\n",
    "            continue\n",
    "        noise_normal = noise_normals[ni]\n",
    "\n",
    "        # Find neighboring real clusters\n",
    "        neighbor_real_candidates = set()\n",
    "        for fi in noise:\n",
    "            for fj in face_adjacency.get(fi, []):\n",
    "                if fj in face_to_real_cluster:\n",
    "                    neighbor_real_candidates.add(face_to_real_cluster[fj])\n",
    "\n",
    "        # Find best-matching real cluster\n",
    "        best_real_idx = None\n",
    "        best_angle = float('inf')\n",
    "\n",
    "        for r_idx in neighbor_real_candidates:\n",
    "            angle = normal_vector_angle(noise_normal, real_normals[r_idx])\n",
    "            if angle < best_angle:\n",
    "                best_real_idx = r_idx\n",
    "                best_angle = angle\n",
    "\n",
    "        # Merge noise into the best real cluster\n",
    "        if best_real_idx is not None:\n",
    "            real_clusters[best_real_idx].update(noise)\n",
    "            merged_indices.add(ni)\n",
    "\n",
    "    return real_clusters\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    This code implement the Laplace smoothing algorithm mentioned in the section 2 of the paper \n",
    "    \"Robust surface segmentation and edge feature lines extraction from fractured\n",
    "    ragments of relics\" \n",
    "'''\n",
    "\n",
    "\n",
    "# ---------- Laplacian Smoothing Functions ----------\n",
    "\n",
    "def build_vertex_adjacency(faces: np.ndarray) -> dict[int, set[int]]:\n",
    "    \"\"\"\n",
    "    Get adjacency of all vertices in the mesh.\n",
    "\n",
    "    Parameters:\n",
    "        faces (np.ndarray): An (N, 3) array where each row contains three vertex indices representing a triangle.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, set[int]]: Dictionary mapping each vertex to a set of its adjacent vertices.\n",
    "    \"\"\"\n",
    "    adjacency: dict[int, set[int]] = defaultdict(set)\n",
    "\n",
    "    for i, j, k in faces:\n",
    "        adjacency[i].update((j, k))\n",
    "        adjacency[j].update((i, k))\n",
    "        adjacency[k].update((i, j))\n",
    "\n",
    "    return adjacency\n",
    "\n",
    "def build_face_adjacency(faces):\n",
    "    \"\"\"\n",
    "    Build face adjacency dictionary. Two faces are adjacent if they share exactly two vertices (i.e., share an edge).\n",
    "\n",
    "    Parameters:\n",
    "        faces (np.ndarray): An (M, 3) array of triangle vertex indices.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, set[int]]: Mapping from face index to set of neighboring face indices.\n",
    "    \"\"\"\n",
    "    edge_to_faces = defaultdict(set)\n",
    "\n",
    "    # Step 1: Map each edge to the faces that contain it\n",
    "    for face_idx, (i, j, k) in enumerate(faces):\n",
    "        edges = [\n",
    "            tuple(sorted((i, j))),\n",
    "            tuple(sorted((j, k))),\n",
    "            tuple(sorted((k, i)))\n",
    "        ]\n",
    "        for edge in edges:\n",
    "            edge_to_faces[edge].add(face_idx)\n",
    "\n",
    "    # Step 2: Build face adjacency based on shared edges\n",
    "    face_adjacency = defaultdict(set)\n",
    "    for edge, face_indices in edge_to_faces.items():\n",
    "        if len(face_indices) < 2:\n",
    "            continue  # not a shared edge\n",
    "        face_indices = list(face_indices)\n",
    "        for i in range(len(face_indices)):\n",
    "            for j in range(i + 1, len(face_indices)):\n",
    "                fi, fj = face_indices[i], face_indices[j]\n",
    "                face_adjacency[fi].add(fj)\n",
    "                face_adjacency[fj].add(fi)\n",
    "\n",
    "    return dict(face_adjacency)\n",
    "\n",
    "def weighted_laplacian_smoothing(vertices, faces, iterations=1):\n",
    "    vertices = vertices.copy()\n",
    "    adjacency = build_vertex_adjacency(faces)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        new_vertices = vertices.copy()\n",
    "        for i in range(vertices.shape[0]):\n",
    "            neighbors = list(adjacency[i])\n",
    "            if not neighbors:\n",
    "                continue\n",
    "\n",
    "            neighbors_coords = vertices[neighbors]  # shape: (N_neighbors, 3)\n",
    "            diffs = neighbors_coords - vertices[i]  # shape: (N_neighbors, 3)\n",
    "            dists = np.linalg.norm(diffs, axis=1) + 1e-8  # avoid zero division\n",
    "            weights = 1.0 / dists\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            weighted_sum = np.dot(weights, diffs)  # shape: (3,)\n",
    "            new_vertices[i] += weighted_sum\n",
    "\n",
    "        vertices = new_vertices\n",
    "\n",
    "    return vertices\n",
    "\n",
    "\n",
    "def laplacian_smoothing(mesh: pv.PolyData, iterations=3):\n",
    "    \n",
    "    # Extract face indices (reshape from PyVista's format)\n",
    "    faces = mesh.faces.reshape((-1, 4))[:, 1:]  # Drop the leading \"3\" of each triangle\n",
    "    adjacency = build_vertex_adjacency(faces)\n",
    "\n",
    "    points = mesh.points.copy()\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        new_points = points.copy()\n",
    "        for i in range(len(points)):\n",
    "            neighbors = list(adjacency[i])\n",
    "            if not neighbors:\n",
    "                continue\n",
    "            neighbor_coords = points[neighbors]\n",
    "            new_points[i] = neighbor_coords.mean(axis=0)\n",
    "        points = new_points  # update for next iteration\n",
    "\n",
    "    # Create a new smoothed mesh to avoid altering the original\n",
    "    smoothed_mesh = pv.PolyData(points, mesh.faces)\n",
    "    return smoothed_mesh\n",
    "\n",
    "def compute_mesh_smoothness(vertices, faces): # To see how much a mesh is smooth\n",
    "    adjacency = build_vertex_adjacency(faces)\n",
    "    smoothness_vals = []\n",
    "\n",
    "    for i in range(len(vertices)):\n",
    "        neighbors = list(adjacency[i])\n",
    "        if not neighbors:\n",
    "            continue\n",
    "        avg_neighbor = np.mean(vertices[neighbors], axis=0)\n",
    "        smoothness = np.linalg.norm(vertices[i] - avg_neighbor)\n",
    "        smoothness_vals.append(smoothness)\n",
    "\n",
    "    return np.mean(smoothness_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf475f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_builtin_int(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {convert_to_builtin_int(k): convert_to_builtin_int(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_builtin_int(i) for i in obj]\n",
    "    elif isinstance(obj, set):\n",
    "        return {convert_to_builtin_int(i) for i in obj}\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(convert_to_builtin_int(i) for i in obj)\n",
    "    elif isinstance(obj, np.integer):  # Catch np.int64, np.int32, ...\n",
    "        return int(obj)\n",
    "    else:\n",
    "        return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9328c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyvista as pv\n",
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "mesh = pv.read('../CG_dataset/cuboctahedron_subdivide.obj') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334092ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faces_1D = mesh.faces\n",
    "# faces_nD = faces_1D.reshape((-1, 4))[:, 1:]\n",
    "\n",
    "# smoothed_vertices = weighted_laplacian_smoothing(mesh.points, faces_nD, 3)\n",
    "# smoothed_mesh = pv.PolyData(smoothed_vertices, faces_1D)\n",
    "\n",
    "# import gc\n",
    "# del mesh\n",
    "# del smoothed_vertices\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba9403",
   "metadata": {},
   "source": [
    "## Laplacian Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac3cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_mesh = laplacian_smoothing(mesh, iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d2653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "vertices = smoothed_mesh.points \n",
    "faces_1D = smoothed_mesh.faces\n",
    "faces_nD = smoothed_mesh.faces.reshape((-1, 4))[:, 1:]\n",
    "\n",
    "del faces_1D\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23db0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = build_vertex_adjacency(faces_nD)\n",
    "adj = convert_to_builtin_int(adj)\n",
    "\n",
    "f_adj = build_face_adjacency(faces_nD)\n",
    "f_adj = convert_to_builtin_int(f_adj)\n",
    "\n",
    "v_normals = compute_area_weighted_vertex_normals(smoothed_mesh)\n",
    "\n",
    "# f_normals = compute_face_normals_from_vertex_normals(faces_nD, v_normals)\n",
    "f_normals, _ = compute_face_normals_and_areas(smoothed_mesh)\n",
    "\n",
    "# flat_v_sorted = sorting_flat_vertices_with_flatness(v_normals, adj)\n",
    "# flat_v_sorted = [vertex for vertex, flatness in flat_v_sorted]\n",
    "# flat_v_sorted = convert_to_builtin_int(flat_v_sorted)\n",
    "\n",
    "flat_f_sorted = sort_faces_by_flatness(f_normals, f_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ccb0a",
   "metadata": {},
   "source": [
    "## Surface Segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee7ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = cluster_surface(adj, v_normals, flat_v_sorted, 0.5, 0.55)\n",
    "clusters = cluster_surface_face_based(f_adj, f_normals, flat_f_sorted, 0.5, 0.4)\n",
    "#brick1: 0.4\n",
    "#brick2: 0.5\n",
    "#brick3: 0.5\n",
    "#brick4: 0.4\n",
    "#brick5: 0.4\n",
    "#brick6: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5eda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove noise faces\n",
    "# merged = merge_noise_faces(clusters, v_normals, adj, K=10)\n",
    "merged = merge_noise_faces_face_based(clusters, f_normals, f_adj, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca1de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\n",
    "#     'red', 'green', 'blue', 'yellow', 'magenta', 'cyan',\n",
    "#     'orange', 'lime', 'deeppink', 'deepskyblue', 'gold',\n",
    "#     'indigo', 'teal', 'crimson', 'mediumvioletred',\n",
    "#     'chartreuse', 'orangered', 'darkturquoise',\n",
    "#     'slateblue', 'darkgoldenrod'\n",
    "# ]\n",
    "\n",
    "# plotter = pv.Plotter(shape=(1, 3))\n",
    "\n",
    "# plotter.subplot(0, 0)\n",
    "# plotter.add_title(\"Original\")\n",
    "# plotter.add_mesh(mesh, show_edges=True)\n",
    "\n",
    "# plotter.subplot(0, 1)\n",
    "# plotter.add_title(\"Clusters\")\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for i, cluster in enumerate(clusters):\n",
    "#     cluster_indices = list(cluster)\n",
    "#     color = colors[i % len(colors)]\n",
    "#     plotter.add_mesh(smoothed_mesh.points[cluster_indices], color=color, point_size=10, render_points_as_spheres=True)\n",
    "\n",
    "\n",
    "# plotter.subplot(0, 2)\n",
    "# plotter.add_title(\"Merged\")\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for i, cluster in enumerate(merged):\n",
    "#     merged_indices = list(cluster)\n",
    "#     color = colors[i % len(colors)]\n",
    "#     # if i == 2:\n",
    "#     #     color = 'white'\n",
    "#     plotter.add_mesh(smoothed_mesh.points[merged_indices], color=color, point_size=10, render_points_as_spheres=True)\n",
    "\n",
    "# plotter.link_views()\n",
    "# plotter.show()\n",
    "\n",
    "# import gc\n",
    "# del colors, color, i, plotter, cluster_indices, merged_indices, cluster\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de634014",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125aaff3",
   "metadata": {},
   "source": [
    "### Edge Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5dcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_cluster_edge_points(clusters, adj):\n",
    "#     \"\"\"\n",
    "#     Identify edge points in each cluster based on adjacency.\n",
    "\n",
    "#     Args:\n",
    "#         clusters (List[Set[int]]): List of clusters, each a set of vertex indices.\n",
    "#         adj (Dict[int, Set[int]]): Vertex adjacency list.\n",
    "\n",
    "#     Returns:\n",
    "#         List[Set[int]]: List of sets, each containing the edge vertex indices for that cluster.\n",
    "#     \"\"\"\n",
    "#     cluster_edge_points = []\n",
    "\n",
    "#     for cluster in clusters:\n",
    "#         visited = set()\n",
    "#         edge_points = set()\n",
    "#         queue = deque()\n",
    "\n",
    "#         # Initialize BFS with any point in the cluster\n",
    "#         if not cluster:\n",
    "#             cluster_edge_points.append(set())\n",
    "#             continue\n",
    "#         start = next(iter(cluster))\n",
    "#         queue.append(start)\n",
    "#         visited.add(start)\n",
    "\n",
    "#         while queue:\n",
    "#             vi = queue.popleft()\n",
    "#             for vj in adj[vi]:\n",
    "#                 if vj not in cluster:\n",
    "#                     edge_points.add(vi)\n",
    "#                 elif vj not in visited:\n",
    "#                     visited.add(vj)\n",
    "#                     queue.append(vj)\n",
    "\n",
    "#         cluster_edge_points.append(edge_points)\n",
    "\n",
    "#     return cluster_edge_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf2cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_points_per_cluster = find_cluster_edge_points(merged, adj)\n",
    "# # Combine all edge points from all clusters\n",
    "# all_edge_points = set()\n",
    "# for edge_set in edge_points_per_cluster:\n",
    "#     all_edge_points.update(edge_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f33e2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\n",
    "#     'red', 'green', 'blue', 'yellow', 'magenta', 'cyan',\n",
    "#     'orange', 'lime', 'deeppink', 'deepskyblue', 'gold',\n",
    "#     'indigo', 'teal', 'crimson', 'mediumvioletred',\n",
    "#     'chartreuse', 'orangered', 'darkturquoise',\n",
    "#     'slateblue', 'darkgoldenrod'\n",
    "# ]\n",
    "\n",
    "# plotter = pv.Plotter(shape=(1, 2))\n",
    "    \n",
    "# plotter.subplot(0, 0)\n",
    "# plotter.add_title(\"Remove Noise Faces\")\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for i, cluster in enumerate(merged):\n",
    "#     merged_indices = list(cluster)\n",
    "#     color = colors[i % len(colors)]\n",
    "#     plotter.add_mesh(smoothed_mesh.points[merged_indices], color=color, point_size=10)\n",
    "\n",
    "# plotter.subplot(0, 1)\n",
    "# # Extract coordinates of all edge points\n",
    "# plotter.add_title(\"Edges\")\n",
    "# edge_coords = smoothed_mesh.points[list(all_edge_points)]\n",
    "# point_cloud = pv.PolyData(edge_coords)\n",
    "# # Plot edge points\n",
    "# plotter.add_mesh(point_cloud, color='red', point_size=5)\n",
    "\n",
    "\n",
    "# plotter.link_views()\n",
    "# plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da430b",
   "metadata": {},
   "source": [
    "### Edge Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6879aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_edge_faces(clusters, face_adjacency):\n",
    "    \"\"\"\n",
    "    Identify edge faces in each cluster based on face adjacency.\n",
    "    A face is considered an edge face if it has any neighbor outside its cluster.\n",
    "\n",
    "    Args:\n",
    "        clusters (List[Set[int]]): List of face clusters (each a set of face indices).\n",
    "        face_adjacency (Dict[int, Set[int]]): Face adjacency map.\n",
    "\n",
    "    Returns:\n",
    "        List[Set[int]]: List of sets, each containing edge face indices per cluster.\n",
    "    \"\"\"\n",
    "    cluster_edge_faces = []\n",
    "\n",
    "    for cluster in clusters:\n",
    "        edge_faces = set()\n",
    "\n",
    "        for face in cluster:\n",
    "            neighbors = face_adjacency.get(face, set())\n",
    "            if any(n not in cluster for n in neighbors):\n",
    "                edge_faces.add(face)\n",
    "\n",
    "        cluster_edge_faces.append(edge_faces)\n",
    "\n",
    "    return cluster_edge_faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d008248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_faces_per_cluster = find_cluster_edge_faces(merged, f_adj)\n",
    "# all_edge_faces = set().union(*edge_faces_per_cluster)\n",
    "\n",
    "# colors = [\n",
    "#     'red', 'green', 'blue', 'yellow', \n",
    "#     'aliceblue', 'magenta', 'cyan', 'orange', \n",
    "#     'lime', 'deeppink', 'darkgray', 'yellowgreen', \n",
    "#     'sienna', 'indigo', 'teal', 'purple', \n",
    "#     'salmon', 'navy', 'darkgoldenrod', 'black'\n",
    "# ]\n",
    "\n",
    "# plotter = pv.Plotter(shape=(2, 2))\n",
    "\n",
    "# # ========== Subplot 0: Original ==========\n",
    "# plotter.subplot(0, 0)\n",
    "# plotter.add_title(\"Original\")\n",
    "# plotter.add_mesh(mesh, show_edges=True)\n",
    "\n",
    "# # ========== Subplot 1: Clusters ==========\n",
    "# plotter.subplot(0, 1)\n",
    "# plotter.add_title(\"Clusters\")\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for j, cluster in enumerate(clusters):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     color = colors[j % len(colors)]\n",
    "#     plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#     )\n",
    "\n",
    "# # ========== Subplot 2: Merged ==========\n",
    "# plotter.subplot(1, 0)\n",
    "# plotter.add_title(\"Merged\")\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for j, cluster in enumerate(merged):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     color = colors[j % len(colors)]\n",
    "#     plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#     )\n",
    "\n",
    "# # === Subplot (1, 1): Edge Faces ===\n",
    "# plotter.subplot(1, 1)\n",
    "# plotter.add_title(\"Edges\")\n",
    "# # plotter.add_mesh(smoothed_mesh, opacity=0.1, show_edges=True)\n",
    "\n",
    "# # Extract edge faces as cells\n",
    "# edge_face_mask = np.zeros(smoothed_mesh.n_cells, dtype=bool)\n",
    "# edge_face_mask[list(all_edge_faces)] = True\n",
    "# edge_part = smoothed_mesh.extract_cells(edge_face_mask)\n",
    "# plotter.add_mesh(edge_part, color='orange', show_edges=True)\n",
    "\n",
    "# # Hiển thị\n",
    "# plotter.link_views()\n",
    "# plotter.show()\n",
    "\n",
    "# # Cleanup (tùy chọn)\n",
    "# # import gc\n",
    "# # del colors, i, cluster, face_indices, cell_mask, edge_face_mask, plotter\n",
    "# # gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd71f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_faces_per_cluster = find_cluster_edge_faces(merged, f_adj)\n",
    "# all_edge_faces = set().union(*edge_faces_per_cluster)\n",
    "\n",
    "# colors = [\n",
    "#     'red', 'green', 'blue', 'yellow', \n",
    "#     'aliceblue', 'magenta', 'cyan', 'orange', \n",
    "#     'lime', 'deeppink', 'darkgray', 'yellowgreen', \n",
    "#     'sienna', 'indigo', 'teal', 'purple', \n",
    "#     'salmon', 'navy', 'darkgoldenrod', 'black'\n",
    "# ]\n",
    "\n",
    "# plotter = pv.Plotter(shape=(1, 2))\n",
    "\n",
    "# # ========== Subplot 0: Original ==========\n",
    "# plotter.subplot(0, 0)\n",
    "# plotter.add_text(\"Surface segmentation\", font_size=15)\n",
    "# plotter.add_mesh(smoothed_mesh)\n",
    "# for j, cluster in enumerate(clusters):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     color = colors[j % len(colors)]\n",
    "#     plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#     )\n",
    "\n",
    "# # ========== Subplot 1: Clusters ==========\n",
    "# plotter.subplot(0, 1)\n",
    "# # plotter.add_text(\"Surface segmentation\", font_size=15)\n",
    "# plotter.add_mesh(smoothed_mesh)\n",
    "# for j, cluster in enumerate(clusters):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     color = colors[j % len(colors)]\n",
    "#     plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#     )\n",
    "\n",
    "# # Hiển thị\n",
    "# # plotter.link_views()\n",
    "# plotter.show()\n",
    "\n",
    "# # Cleanup (tùy chọn)\n",
    "# # import gc\n",
    "# # del colors, i, cluster, face_indices, cell_mask, edge_face_mask, plotter\n",
    "# # gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb00ef",
   "metadata": {},
   "source": [
    "## PCA Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d30ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(merged)):\n",
    "    surface = merged[j]\n",
    "\n",
    "    surface_p_id = list()\n",
    "    for j, f_id in enumerate(surface):\n",
    "        p_ids = smoothed_mesh.get_cell(f_id).point_ids\n",
    "        surface_p_id.extend(p_ids)\n",
    "\n",
    "    surface_p_id = set(surface_p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b4dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "real_clusters = list()\n",
    "noise_clusters = list()\n",
    "\n",
    "pca_width_threshold = 0.6\n",
    "\n",
    "for _, f_cluster in enumerate(merged):\n",
    "    surface_p_id = list()\n",
    "    for j, f_id in enumerate(f_cluster):\n",
    "        p_ids = smoothed_mesh.get_cell(f_id).point_ids\n",
    "        surface_p_id.extend(p_ids)\n",
    "\n",
    "    surface_p_id = set(surface_p_id)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    transformed = pca.fit_transform(smoothed_mesh.points[list(surface_p_id)])   \n",
    "\n",
    "    # 2. Chiều dài: dọc theo PC1\n",
    "    pca_length = transformed[:, 0].max() - transformed[:, 0].min()  \n",
    "\n",
    "    # 3. Chiều rộng: dọc theo PC2\n",
    "    pca_width = transformed[:, 1].max() - transformed[:, 1].min()\n",
    "\n",
    "    if pca_width < pca_width_threshold:\n",
    "        noise_clusters.append(f_cluster)\n",
    "\n",
    "    else:\n",
    "        real_clusters.append(f_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4702a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis_colors = ['red', 'blue', 'yellow']\n",
    "\n",
    "# polydata = pv.PolyData(smoothed_mesh.points[list(surface_p_id)])\n",
    "\n",
    "# center = polydata.center\n",
    "\n",
    "# # Chiều dài trục để hiển thị\n",
    "# scale = 0.3 * smoothed_mesh.length\n",
    "\n",
    "# # Tạo các Line object cho từng trục (xuất phát từ center)\n",
    "# lines = [\n",
    "#     pv.Line(center, center + axis * scale) for axis in axes\n",
    "# ]\n",
    "\n",
    "# # Hiển thị cùng với mesh\n",
    "# plotter = pv.Plotter()\n",
    "\n",
    "# # Hiển thị lưới smoothed_mesh\n",
    "# # plotter.add_mesh(smoothed_mesh, show_edges=True, opacity=0.3)\n",
    "# for i, cluster in enumerate(merged):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     if i == surface_index:\n",
    "#         color = colors[i % len(colors)]\n",
    "#         plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#         )   \n",
    "\n",
    "# # Hiển thị các trục chính màu đỏ\n",
    "# for line in lines:\n",
    "#     plotter.add_mesh(line, color='red', line_width=1)\n",
    "\n",
    "# for i in range(3):\n",
    "#     plotter.add_mesh(lines[i], color=axis_colors[i])\n",
    "\n",
    "# plotter.show()\n",
    "\n",
    "# # NOTE: Project the surfaces onto 2D space and find principal component - easier than working in 3d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a8dc8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# surface_index = 31\n",
    "# surface_p_id = list()\n",
    "# for j, c in enumerate(merged):\n",
    "#     if j == surface_index:\n",
    "#         for f_id in c:\n",
    "#             p_id = smoothed_mesh.get_cell(f_id).point_ids\n",
    "#             surface_p_id.extend(p_id)\n",
    "# surface_p_id = set(surface_p_id)\n",
    "\n",
    "# # 1. Áp dụng PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# transformed = pca.fit_transform(smoothed_mesh.points[list(surface_p_id)])\n",
    "\n",
    "# # 2. Chiều dài: dọc theo PC1\n",
    "# pca_length = transformed[:, 0].max() - transformed[:, 0].min()\n",
    "\n",
    "# # 3. Chiều rộng: dọc theo PC2\n",
    "# pca_width = transformed[:, 1].max() - transformed[:, 1].min()\n",
    "\n",
    "# print(\"Chiều dài (PC1):\", pca_length)\n",
    "# print(\"Chiều rộng (PC2):\", pca_width)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(transformed[:, 0], transformed[:, 1], alpha=0.3,\n",
    "#             color=colors[surface_index % len(colors)])\n",
    "# plt.axvline(0, color='red', label='PC1')\n",
    "# plt.axhline(0, color='blue', label='PC2')\n",
    "\n",
    "# # Thêm text vào ảnh\n",
    "# # info_text = f\"Length (PC1): {pca_length:.2f}\\nWidth (PC2): {pca_width:.2f}\"\n",
    "# # plt.text(-3, 2.8, info_text, fontsize=10, color='black',\n",
    "# #          bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.3'))\n",
    "\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.title('Surface in PCA')\n",
    "# plt.xlabel('PC1')\n",
    "# plt.ylabel('PC2')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf3308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# surface_indices = [0, 2, 30, 31]  # 4 surface muốn hiển thị\n",
    "# # colors = ['blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# for idx, s_index in enumerate(surface_indices):\n",
    "#     surface_p_id = []\n",
    "#     for j, c in enumerate(merged):\n",
    "#         if j == s_index:\n",
    "#             for f_id in c:\n",
    "#                 p_id = smoothed_mesh.get_cell(f_id).point_ids\n",
    "#                 surface_p_id.extend(p_id)\n",
    "\n",
    "#     surface_p_id = list(set(surface_p_id))  # loại bỏ trùng lặp\n",
    "\n",
    "#     if len(surface_p_id) == 0:\n",
    "#         print(f\"⚠️ Surface {s_index} has no points — skipped.\")\n",
    "#         continue\n",
    "\n",
    "#     # PCA\n",
    "#     points = smoothed_mesh.points[surface_p_id]\n",
    "#     pca = PCA(n_components=2)\n",
    "#     transformed = pca.fit_transform(points)\n",
    "\n",
    "#     pca_length = transformed[:, 0].max() - transformed[:, 0].min()\n",
    "#     pca_width = transformed[:, 1].max() - transformed[:, 1].min()\n",
    "\n",
    "#     ax = axs[idx]\n",
    "#     ax.scatter(transformed[:, 0], transformed[:, 1], alpha=0.3,\n",
    "#                color=colors[idx % len(colors)])\n",
    "#     # ax.axvline(0, color='red', label='PC1')\n",
    "#     # ax.axhline(0, color='blue', label='PC2')\n",
    "#     ax.set_title(f'Surface {s_index} in PCA\\nLength: {pca_length:.2f}, Width: {pca_width:.2f}')\n",
    "#     ax.set_xlabel('PC1')\n",
    "#     ax.set_ylabel('PC2')\n",
    "#     ax.axis('equal')\n",
    "#     ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6ee2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_noise_faces_face_based(clusters, face_normals, face_adjacency, real_clusters, noise_clusters):\n",
    "    \"\"\"\n",
    "    Merge small (noise) face clusters into neighboring real clusters based on normal similarity,\n",
    "    while avoiding merging adjacent noise clusters together.\n",
    "\n",
    "    Parameters:\n",
    "        clusters (List[Set[int]]): List of face index sets (each cluster).\n",
    "        face_normals (np.ndarray): (M, 3) array of face normals.\n",
    "        face_adjacency (dict[int, set[int]]): Adjacency list of faces.\n",
    "\n",
    "    Returns:\n",
    "        List[Set[int]]: Updated clusters with noise faces merged into real face clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute average normal of a cluster\n",
    "    def cluster_avg_normal(cluster):\n",
    "        normals = [face_normals[fi] for fi in cluster]\n",
    "        summed = np.sum(normals, axis=0)\n",
    "        norm = np.linalg.norm(summed)\n",
    "        return summed / norm if norm > 0 else summed\n",
    "\n",
    "    real_normals = [cluster_avg_normal(c) for c in real_clusters]\n",
    "    noise_normals = [cluster_avg_normal(c) for c in noise_clusters]\n",
    "\n",
    "    # Map each face to its real cluster (for fast lookup)\n",
    "    face_to_real_cluster = {}\n",
    "    for idx, cluster in enumerate(real_clusters):\n",
    "        for f in cluster:\n",
    "            face_to_real_cluster[f] = idx\n",
    "\n",
    "    merged_indices = set()  # to skip already-merged noise clusters\n",
    "\n",
    "    for ni, noise in enumerate(noise_clusters):\n",
    "        if ni in merged_indices:\n",
    "            continue\n",
    "        noise_normal = noise_normals[ni]\n",
    "\n",
    "        # Find neighboring real clusters\n",
    "        neighbor_real_candidates = set()\n",
    "        for fi in noise:\n",
    "            for fj in face_adjacency.get(fi, []):\n",
    "                if fj in face_to_real_cluster:\n",
    "                    neighbor_real_candidates.add(face_to_real_cluster[fj])\n",
    "\n",
    "        # Find best-matching real cluster\n",
    "        best_real_idx = None\n",
    "        best_angle = float('inf')\n",
    "\n",
    "        for r_idx in neighbor_real_candidates:\n",
    "            angle = normal_vector_angle(noise_normal, real_normals[r_idx])\n",
    "            if angle < best_angle:\n",
    "                best_real_idx = r_idx\n",
    "                best_angle = angle\n",
    "\n",
    "        # Merge noise into the best real cluster\n",
    "        if best_real_idx is not None:\n",
    "            real_clusters[best_real_idx].update(noise)\n",
    "            merged_indices.add(ni)\n",
    "\n",
    "    return real_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41d371b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_noise_faces_face_based(merged, f_normals, f_adj, real_clusters, noise_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fc61fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a1b62cc70844cabc74394b39627cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:39751/index.html?ui=P_0x7762ed2cc200_0&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_faces_per_cluster = find_cluster_edge_faces(merged, f_adj)\n",
    "all_edge_faces = set().union(*edge_faces_per_cluster)\n",
    "\n",
    "colors = [\n",
    "    'red', 'green', 'blue', 'yellow', \n",
    "    'aliceblue', 'magenta', 'cyan', 'orange', \n",
    "    'lime', 'deeppink', 'darkgray', 'yellowgreen', \n",
    "    'sienna', 'indigo', 'teal', 'purple', \n",
    "    'salmon', 'navy', 'darkgoldenrod', 'black'\n",
    "]\n",
    "\n",
    "plotter = pv.Plotter(shape=(1, 2))\n",
    "\n",
    "# # ========== Subplot 0: Original ==========\n",
    "plotter.subplot(0, 0)\n",
    "# plotter.add_title(\"Original\")\n",
    "plotter.add_mesh(mesh, show_edges=True, color='aliceblue')\n",
    "\n",
    "# # ========== Subplot 1: Clusters ==========\n",
    "# plotter.subplot(0, 1)\n",
    "# plotter.add_title(\"Clusters\")\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for j, cluster in enumerate(clusters):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     color = colors[j % len(colors)]\n",
    "#     plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#     )\n",
    "\n",
    "# ========== Subplot 2: Merged ==========\n",
    "# plotter.subplot(0, 0)\n",
    "# plotter.add_text(\"Long and thin faces merging\", font_size=15)\n",
    "# plotter.add_mesh(smoothed_mesh, show_edges=True)\n",
    "# for j, cluster in enumerate(merged):\n",
    "#     face_indices = list(cluster)\n",
    "#     point_indices = np.unique(faces_nD[face_indices].flatten())\n",
    "#     color = colors[j % len(colors)]\n",
    "#     plotter.add_mesh(\n",
    "#         smoothed_mesh.extract_points(point_indices, adjacent_cells=False),\n",
    "#         color=color,\n",
    "#         point_size=10,\n",
    "#         render_points_as_spheres=True\n",
    "#     )\n",
    "\n",
    "# === Subplot (1, 1): Edge Faces ===\n",
    "plotter.subplot(0, 1)\n",
    "# plotter.add_text(\"Edges\", font_size=12)\n",
    "# plotter.add_mesh(smoothed_mesh, opacity=0.1, show_edges=True)\n",
    "\n",
    "# Extract edge faces as cells\n",
    "edge_face_mask = np.zeros(smoothed_mesh.n_cells, dtype=bool)\n",
    "edge_face_mask[list(all_edge_faces)] = True\n",
    "edge_part = smoothed_mesh.extract_cells(edge_face_mask)\n",
    "plotter.add_mesh(edge_part, color='orange', show_edges=True)\n",
    "\n",
    "# Hiển thị\n",
    "plotter.link_views()\n",
    "plotter.show(window_size=(2000, 1000))\n",
    "\n",
    "# Cleanup (tùy chọn)\n",
    "# import gc\n",
    "# del colors, i, cluster, face_indices, cell_mask, edge_face_mask, plotter\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f0b41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running times (s): 5.7506797313690186\n"
     ]
    }
   ],
   "source": [
    "time_end = time.time()\n",
    "\n",
    "print(f\"Running times (s): {time_end - time_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fd59de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style='width: 100%;'><tr><th>Header</th><th>Data Arrays</th></tr><tr><td>\n",
       "<table style='width: 100%;'>\n",
       "<tr><th>PolyData</th><th>Information</th></tr>\n",
       "<tr><td>N Cells</td><td>20480</td></tr>\n",
       "<tr><td>N Points</td><td>10242</td></tr>\n",
       "<tr><td>N Strips</td><td>0</td></tr>\n",
       "<tr><td>X Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>Y Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>Z Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>N Arrays</td><td>1</td></tr>\n",
       "</table>\n",
       "\n",
       "</td><td>\n",
       "<table style='width: 100%;'>\n",
       "<tr><th>Name</th><th>Field</th><th>Type</th><th>N Comp</th><th>Min</th><th>Max</th></tr>\n",
       "<tr><td>GroupIds</td><td>Cells</td><td>float32</td><td>1</td><td>0.000e+00</td><td>0.000e+00</td></tr>\n",
       "</table>\n",
       "\n",
       "</td></tr> </table>"
      ],
      "text/plain": [
       "PolyData (0x7762b85c0820)\n",
       "  N Cells:    20480\n",
       "  N Points:   10242\n",
       "  N Strips:   0\n",
       "  X Bounds:   -1.000e+00, 1.000e+00\n",
       "  Y Bounds:   -1.000e+00, 1.000e+00\n",
       "  Z Bounds:   -1.000e+00, 1.000e+00\n",
       "  N Arrays:   1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6940c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nbformat\n",
    "\n",
    "# # 📌 BƯỚC 1: Đặt tên file notebook và file xuất ra\n",
    "# notebook_file = \"RobustSurfaceSeg_EdgeExtract.ipynb\"     # 👉 đổi thành tên notebook của bạn\n",
    "# output_file = \"extract_code_from_ipynb.py\"      # 👉 tên file .py để lưu code\n",
    "\n",
    "# # 📌 BƯỚC 2: Đọc file notebook\n",
    "# with open(notebook_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# # 📌 BƯỚC 3: Giả sử ô hiện tại đang chạy là ô cuối cùng (có thể điều chỉnh nếu cần)\n",
    "# current_cell_index = len(nb.cells) - 1\n",
    "\n",
    "# # 📌 BƯỚC 4: Lấy code từ tất cả các cell code phía trên\n",
    "# code_above = \"\"\n",
    "# for i in range(current_cell_index):\n",
    "#     cell = nb.cells[i]\n",
    "#     if cell.cell_type == \"code\":\n",
    "#         code_above += cell.source + \"\\n\\n\"\n",
    "\n",
    "# # 📌 BƯỚC 5: Lưu vào file .py\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(code_above)\n",
    "\n",
    "# print(f\"✅ Đã lưu mã từ các cell phía trên vào file: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3D",
   "language": "python",
   "name": "project3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
